{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6fe23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # One weight matrix for all gates\n",
    "        self.xh2gates = nn.Linear(input_size + hidden_size, 4 * hidden_size)\n",
    "\n",
    "    def forward(self, x_t, h_prev, c_prev):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_t: (batch_size, input_size)\n",
    "            h_prev: (batch_size, hidden_size)\n",
    "            c_prev: (batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        combined = torch.cat([x_t, h_prev], dim=1) # (batch_size, input_size + hidden_size)\n",
    "        gates = self.xh2gates(combined) # (batch_size, 4 * hidden_size)\n",
    "\n",
    "        f_t, i_t, o_t, c__t = torch.chunk(gates, 4, dim=1)\n",
    "\n",
    "        f_t = torch.sigmoid(f_t) # forget gate\n",
    "        i_t = torch.sigmoid(i_t) # input gate\n",
    "        o_t = torch.sigmoid(o_t) # output gate\n",
    "        c__t = torch.tanh(c__t) # candidate cell state\n",
    "\n",
    "        c_t = f_t * c_prev + i_t * c__t # new cell state\n",
    "        h_t = o_t * torch.tanh(c_t) # new hidden state\n",
    "\n",
    "        return h_t, c_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b407623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm_cell = CustomLSTMCell(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, input_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        c_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :] # (batch_size, input_size)\n",
    "            h_t, c_t = self.lstm_cell(x_t, h_t, c_t)\n",
    "        \n",
    "        # Use last hidden state for output\n",
    "        out = self.fc(h_t) # (batch_size, output_size)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b931a47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000000, 10, 8])\n",
      "Train size: 800000, Val size: 200000\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "input_size = 8\n",
    "seq_len = 10\n",
    "hidden_size = 64\n",
    "output_size = 1 # binary classification\n",
    "lr = 1e-3\n",
    "epochs =  15\n",
    "\n",
    "# synthetic data\n",
    "N = 1000000\n",
    "X = torch.randn(N, seq_len, input_size)\n",
    "# create labels correlated with the sum of inputs\n",
    "y_logits = X.sum(dim=(1,2))\n",
    "y = (y_logits > 0).float().unsqueeze(1) # binary labels (N, 1)\n",
    "print(X.shape)\n",
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "train_len = int(0.8 * N)\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_len, N - train_len])\n",
    "print(f\"Train size: {len(train_ds)}, Val size: {len(val_ds)}\")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = CustomLSTM(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c52482b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss: 0.1587 | train_acc: 0.9381 | val_loss: 0.0471 | val_acc: 0.9861\n",
      "Epoch 02 | train_loss: 0.0372 | train_acc: 0.9888 | val_loss: 0.0295 | val_acc: 0.9919\n",
      "Epoch 03 | train_loss: 0.0271 | train_acc: 0.9915 | val_loss: 0.0254 | val_acc: 0.9904\n",
      "Epoch 04 | train_loss: 0.0221 | train_acc: 0.9928 | val_loss: 0.0200 | val_acc: 0.9928\n",
      "Epoch 05 | train_loss: 0.0195 | train_acc: 0.9932 | val_loss: 0.0194 | val_acc: 0.9920\n",
      "Epoch 06 | train_loss: 0.0169 | train_acc: 0.9942 | val_loss: 0.0174 | val_acc: 0.9933\n",
      "Epoch 07 | train_loss: 0.0154 | train_acc: 0.9945 | val_loss: 0.0134 | val_acc: 0.9959\n",
      "Epoch 08 | train_loss: 0.0147 | train_acc: 0.9945 | val_loss: 0.0147 | val_acc: 0.9939\n",
      "Epoch 09 | train_loss: 0.0131 | train_acc: 0.9952 | val_loss: 0.0132 | val_acc: 0.9946\n",
      "Epoch 10 | train_loss: 0.0128 | train_acc: 0.9951 | val_loss: 0.0121 | val_acc: 0.9953\n",
      "Epoch 11 | train_loss: 0.0116 | train_acc: 0.9956 | val_loss: 0.0102 | val_acc: 0.9965\n",
      "Epoch 12 | train_loss: 0.0113 | train_acc: 0.9956 | val_loss: 0.0103 | val_acc: 0.9961\n",
      "Epoch 13 | train_loss: 0.0120 | train_acc: 0.9951 | val_loss: 0.0113 | val_acc: 0.9955\n",
      "Epoch 14 | train_loss: 0.0113 | train_acc: 0.9954 | val_loss: 0.0093 | val_acc: 0.9965\n",
      "Epoch 15 | train_loss: 0.0102 | train_acc: 0.9960 | val_loss: 0.0101 | val_acc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in train_dataloader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        logits = model(xb) # forward pass\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # gradient clipping\n",
    "        optimizer.step() # update weights\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0) \n",
    "\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / train_len\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_len = len(val_ds)\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            val_correct += (preds == yb).sum().item()\n",
    "            val_total += yb.size(0)\n",
    "\n",
    "    val_loss = val_loss / val_len\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"Epoch {epoch:02d} | train_loss: {epoch_loss:.4f} | train_acc: {epoch_acc:.4f} \"\n",
    "          f\"| val_loss: {val_loss:.4f} | val_acc: {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve-tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
