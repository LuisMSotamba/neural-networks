{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546630bd-2f5f-4490-a814-f653c60aa0e5",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97aa4c3-83b3-40b6-9c38-98436525a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter existing datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd5235b-5cd3-4184-9700-6debbbf3a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories and file paths\n",
    "DATASET_DIR = \"/media/luchocode/Extra vol/ExoNet_Images/ExoNet_Images\"\n",
    "LABELS_FILE = \"/home/luchocode/Downloads/Labels.csv\"\n",
    "FINAL_DATASETS_DIR = \"/media/luchocode/Extra vol/Datasets/Tesis/\"\n",
    "IMAGE_PATH_FORMAT = \"{}/{}/['{}'] frame {}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ffbc59-6faf-4ec9-8299-e4eccd78614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 922782 entries, 0 to 922781\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   video   922782 non-null  object\n",
      " 1   frame   922782 non-null  int64 \n",
      " 2   class   922782 non-null  object\n",
      " 3   exist   922782 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 22.0+ MB\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(LABELS_FILE)\n",
    "labels[\"exist\"] = labels.apply(lambda row: os.path.exists(\n",
    "    IMAGE_PATH_FORMAT.format(\n",
    "        DATASET_DIR,\n",
    "        row.iloc[2],\n",
    "        row.iloc[0],\n",
    "        row.iloc[1])\n",
    "    ), axis=1)\n",
    "labels = labels[labels[\"exist\"] == True].reset_index(drop=True)\n",
    "labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e555ebd-83d1-45cf-a28f-02ab77766cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions: 39 - 11 - 6\n",
      "Shapes: train-(39,), val-(11,), test-(6,)\n"
     ]
    }
   ],
   "source": [
    "# Generate train, validation and test datasets from the original one\n",
    "np.random.seed(42)\n",
    "video_names = labels[\"video\"].unique()\n",
    "video_names = np.random.choice(video_names, replace=False, size=len(video_names))\n",
    "train_pct = int(len(video_names) * 0.7)\n",
    "val_pct = int(len(video_names) * 0.2)\n",
    "test_pct = int(len(video_names) - (train_pct + val_pct))\n",
    "print(f\"Proportions: {train_pct} - {val_pct} - {test_pct}\")\n",
    "train_videos, val_videos, test_videos = video_names[:train_pct], video_names[train_pct:train_pct+val_pct], video_names[train_pct+val_pct:]\n",
    "print(f\"Shapes: train-{train_videos.shape}, val-{val_videos.shape}, test-{test_videos.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da6fcef2-c8fa-4e8a-9064-5fd8294e6b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train records: 639667, Val records: 174840, Test records: 108275\n"
     ]
    }
   ],
   "source": [
    "train_df = labels[labels[\"video\"].isin(train_videos)]\n",
    "val_df = labels[labels[\"video\"].isin(val_videos)]\n",
    "test_df = labels[labels[\"video\"].isin(test_videos)]\n",
    "print(f\"Train records: {len(train_df)}, Val records: {len(val_df)}, Test records: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112790b4-cc9e-40da-accb-5be9d3a0557f",
   "metadata": {},
   "source": [
    "According to the article where ExoNet database was proposed, each video was downsampled to 5 frames/s to minimize human annotations efforts. Therefore, each 5 video's frames represent 1 second of video recording. \n",
    "\n",
    "Training dataset must be splitted into fixed lenght sequences. Each sequence will represent a past time step (frame) of the video recording. Validation dataset will be splitted into sequences equals to training dataset. All frames in the test dataset will not suffer changes since it will simulate a real time video passed to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56d9ef20-6117-4090-840b-57c23fa6d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] Number of rows obtained after gruping frames per sequence: 641800\n",
      "[Validation] Number of rows obtained after gruping frames per sequence: 175400\n"
     ]
    }
   ],
   "source": [
    "# Sequence length will be set to 100 meaning that 20 past seconds will be considered to classify the current frame\n",
    "SEQUENCE_LENGTH = 100\n",
    "\n",
    "def group_frames_per_sequence(df, seq_len):\n",
    "    splits = len(df) // seq_len\n",
    "    rest_frames = len(df) % seq_len\n",
    "    add_frames = seq_len - rest_frames\n",
    "    \n",
    "    balanced_df = None\n",
    "    for i in range(splits):\n",
    "        _df = df.iloc[i*seq_len:(i+1)*seq_len].copy()\n",
    "        _df[\"video_chunk\"] = f\"chunk_part{i}\"\n",
    "        if balanced_df is None:\n",
    "            balanced_df = _df\n",
    "        else:\n",
    "            balanced_df = pd.concat([balanced_df, _df], axis=0)\n",
    "\n",
    "    if add_frames:\n",
    "        _df = balanced_df.iloc[-seq_len:].copy()\n",
    "        _df[\"video_chunk\"] = f\"chunk_part{splits}\"\n",
    "        balanced_df = pd.concat([balanced_df, _df], axis=0)\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "seq_train_df = train_df.groupby('video', group_keys=False)[['video','frame','class']].apply(lambda x: group_frames_per_sequence(x, SEQUENCE_LENGTH), include_groups=False)\n",
    "seq_train_df = seq_train_df.reset_index(drop=True)\n",
    "\n",
    "seq_val_df = val_df.groupby('video', group_keys=False)[['video','frame','class']].apply(lambda x: group_frames_per_sequence(x, SEQUENCE_LENGTH), include_groups=False)\n",
    "seq_val_df = seq_val_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"[Training] Number of rows obtained after gruping frames per sequence: {len(seq_train_df)}\")\n",
    "print(f\"[Validation] Number of rows obtained after gruping frames per sequence: {len(seq_val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cb32622-55fd-4f4f-a5a5-309399dbb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes\n",
    "seq_train_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"seq_train_df.pkl\"))\n",
    "seq_val_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"seq_val_df.pkl\"))\n",
    "test_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"test_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea77793-09d2-4a54-bc59-4c17bee18cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
