{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546630bd-2f5f-4490-a814-f653c60aa0e5",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97aa4c3-83b3-40b6-9c38-98436525a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter existing datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd5235b-5cd3-4184-9700-6debbbf3a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories and file paths\n",
    "DATASET_DIR = \"/mnt/f/ExoNet_Images/ExoNet_Images\"\n",
    "LABELS_FILE = \"/mnt/f/Descargas/Labels.csv\"\n",
    "FINAL_DATASETS_DIR = \"/mnt/f/Datasets/Tesis/\"\n",
    "IMAGE_PATH_FORMAT = \"{}/{}/['{}'] frame {}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c82152-1b5b-4122-b545-e8101e5a3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels file\n",
    "def read_labels_file(pathdir, name):\n",
    "    try:\n",
    "        return pd.read_pickle(os.path.join(pathdir, name))\n",
    "    except Exception as e:\n",
    "        print(f\"Error when reading the file: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ffbc59-6faf-4ec9-8299-e4eccd78614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 922782 entries, 0 to 922781\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   video   922782 non-null  object\n",
      " 1   frame   922782 non-null  int64 \n",
      " 2   class   922782 non-null  object\n",
      " 3   exist   922782 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 22.0+ MB\n"
     ]
    }
   ],
   "source": [
    "labels = read_labels_file(FINAL_DATASETS_DIR, \"labels_df.pkl\")\n",
    "if not isinstance(labels, pd.DataFrame):\n",
    "    labels = pd.read_csv(LABELS_FILE)\n",
    "    labels[\"exist\"] = labels.apply(lambda row: os.path.exists(\n",
    "        IMAGE_PATH_FORMAT.format(\n",
    "            DATASET_DIR,\n",
    "            row.iloc[2],\n",
    "            row.iloc[0],\n",
    "            row.iloc[1])\n",
    "        ), axis=1)\n",
    "    labels = labels[labels[\"exist\"] == True].reset_index(drop=True)\n",
    "    labels.to_pickle(os.path.join(FINAL_DATASETS_DIR, 'labels_df.pkl'))\n",
    "labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848c052-3207-4add-a744-81bf4422bed9",
   "metadata": {},
   "source": [
    "Los frames de cada video tienen que ser agrupados en secuencia, de tal manera que la clasificación del último frame considere los frames previos de la secuencia. La secuencia elegida serán 20 frames previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e555ebd-83d1-45cf-a28f-02ab77766cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions: 39 - 11 - 6\n",
      "Shapes: train-(39,), val-(11,), test-(6,)\n"
     ]
    }
   ],
   "source": [
    "# Generate train, validation and test datasets from the original one\n",
    "np.random.seed(42)\n",
    "video_names = labels[\"video\"].unique()\n",
    "video_names = np.random.choice(video_names, replace=False, size=len(video_names))\n",
    "train_pct = int(len(video_names) * 0.7)\n",
    "val_pct = int(len(video_names) * 0.2)\n",
    "test_pct = int(len(video_names) - (train_pct + val_pct))\n",
    "print(f\"Proportions: {train_pct} - {val_pct} - {test_pct}\")\n",
    "train_videos, val_videos, test_videos = video_names[:train_pct], video_names[train_pct:train_pct+val_pct], video_names[train_pct+val_pct:]\n",
    "print(f\"Shapes: train-{train_videos.shape}, val-{val_videos.shape}, test-{test_videos.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0306255-c52d-4db8-9ada-b9e63f20e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small dataset to evaluate several models. Choose them from the general training dataset\n",
    "small_train_videos = np.random.choice(train_videos, replace=False, size=5)\n",
    "small_val_videos, small_test_videos, small_train_videos,  = small_train_videos[-2:-1], small_train_videos[-1:], small_train_videos[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da6fcef2-c8fa-4e8a-9064-5fd8294e6b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train records: 639667, Val records: 174840, Test records: 108275\n",
      "Small train records: 53388, Small val records: 17961, Small test records: 9440\n"
     ]
    }
   ],
   "source": [
    "train_df = labels[labels[\"video\"].isin(train_videos)].reset_index(drop=True)\n",
    "val_df = labels[labels[\"video\"].isin(val_videos)].reset_index(drop=True)\n",
    "test_df = labels[labels[\"video\"].isin(test_videos)].reset_index(drop=True)\n",
    "\n",
    "small_train_df = labels[labels[\"video\"].isin(small_train_videos)].reset_index(drop=True)\n",
    "small_val_df = labels[labels[\"video\"].isin(small_val_videos)].reset_index(drop=True)\n",
    "small_test_df = labels[labels[\"video\"].isin(small_test_videos)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train records: {len(train_df)}, Val records: {len(val_df)}, Test records: {len(test_df)}\")\n",
    "print(f\"Small train records: {len(small_train_df)}, Small val records: {len(small_val_df)}, Small test records: {len(small_test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f87103a-10fe-476b-9ea2-8d0c809c36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column containing path route to the file\n",
    "def generate_filepath(row):\n",
    "    return IMAGE_PATH_FORMAT.format(DATASET_DIR,row[\"class\"],row[\"video\"],row[\"frame\"])\n",
    "    \n",
    "train_df.loc[:,'path'] = train_df.apply(generate_filepath, axis=1)\n",
    "val_df.loc[:,'path'] = val_df.apply(generate_filepath, axis=1)\n",
    "test_df.loc[:,'path'] = test_df.apply(generate_filepath, axis=1)\n",
    "\n",
    "small_train_df.loc[:,'path'] = small_train_df.apply(generate_filepath, axis=1)\n",
    "small_val_df.loc[:,'path'] = small_val_df.apply(generate_filepath, axis=1)\n",
    "small_test_df.loc[:,'path'] = small_test_df.apply(generate_filepath, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff60eda-88b8-484d-abfb-dfac341db3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the train_df and val_df datasets\n",
    "train_df.loc[:,'sequence'] = ''\n",
    "val_df.loc[:,'sequence'] = ''\n",
    "small_train_df.loc[:, 'sequence'] = ''\n",
    "small_val_df.loc[:, 'sequence'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324f84bf-cc95-4427-978c-fd4b59123d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 639667 entries, 0 to 639666\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   video     639667 non-null  object\n",
      " 1   frame     639667 non-null  int64 \n",
      " 2   class     639667 non-null  object\n",
      " 3   exist     639667 non-null  bool  \n",
      " 4   path      639667 non-null  object\n",
      " 5   sequence  639667 non-null  object\n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 25.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bceaa41-aca8-406b-b26f-55cd0c309085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53388 entries, 0 to 53387\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   video     53388 non-null  object\n",
      " 1   frame     53388 non-null  int64 \n",
      " 2   class     53388 non-null  object\n",
      " 3   exist     53388 non-null  bool  \n",
      " 4   path      53388 non-null  object\n",
      " 5   sequence  53388 non-null  object\n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "small_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112790b4-cc9e-40da-accb-5be9d3a0557f",
   "metadata": {},
   "source": [
    "According to the article where ExoNet database was proposed, each video was downsampled to 5 frames/s to minimize human annotations efforts. Therefore, each 5 video's frames represent 1 second of video recording. \n",
    "\n",
    "Training dataset must be splitted into fixed lenght sequences. Each sequence will represent a past time step (frame) of the video recording. Validation dataset will be splitted into sequences equals to training dataset. All frames in the test dataset will not suffer changes since it will simulate a real time video passed to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56d9ef20-6117-4090-840b-57c23fa6d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] Number of rows obtained after gruping frames per sequence: 639667\n",
      "[Validation] Number of rows obtained after gruping frames per sequence: 174840\n",
      "[Small training] Number of rows obtained after gruping frames per sequence: 53388\n",
      "[Small validation] Number of rows obtained after gruping frames per sequence: 17961\n"
     ]
    }
   ],
   "source": [
    "# Sequence length will be set to 15 meaning that 3 past seconds will be considered to classify the current frame\n",
    "SEQUENCE_LENGTH = 15\n",
    "\n",
    "def group_frames_per_sequence(df, seq_len):\n",
    "    \"\"\"\n",
    "    Generar secuencias de imágenes de cada video.\n",
    "    [x1,x2,x3,...,xn] -> yn\n",
    "    Esto se traduce a:\n",
    "    [path1,path2,path3,...,path_n] -> yn\n",
    "    \"\"\"\n",
    "    balanced_df = None\n",
    "    _df = df.reset_index(drop=True)\n",
    "    for i in range(seq_len, len(df)+1):\n",
    "        tmp_df = _df.iloc[i-seq_len:i].copy()\n",
    "        _df.at[i-1,\"sequence\"] = \",\".join(tmp_df[\"path\"].to_list())\n",
    "    \n",
    "    return _df\n",
    "\n",
    "seq_train_df = train_df.groupby('video', group_keys=False)[['video','frame','class','path','sequence']].apply(lambda x: group_frames_per_sequence(x, SEQUENCE_LENGTH), include_groups=False)\n",
    "seq_train_df = seq_train_df.reset_index(drop=True)\n",
    "\n",
    "seq_val_df = val_df.groupby('video', group_keys=False)[['video','frame','class','path','sequence']].apply(lambda x: group_frames_per_sequence(x, SEQUENCE_LENGTH), include_groups=False)\n",
    "seq_val_df = seq_val_df.reset_index(drop=True)\n",
    "\n",
    "seq_small_train_df = small_train_df.groupby('video', group_keys=False)[['video','frame','class','path','sequence']].apply(lambda x: group_frames_per_sequence(x, SEQUENCE_LENGTH), include_groups=False)\n",
    "seq_small_train_df = seq_small_train_df.reset_index(drop=True)\n",
    "\n",
    "seq_small_val_df = small_val_df.groupby('video', group_keys=False)[['video','frame','class','path','sequence']].apply(lambda x: group_frames_per_sequence(x, SEQUENCE_LENGTH), include_groups=False)\n",
    "seq_small_val_df = seq_small_val_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"[Training] Number of rows obtained after gruping frames per sequence: {len(seq_train_df)}\")\n",
    "print(f\"[Validation] Number of rows obtained after gruping frames per sequence: {len(seq_val_df)}\")\n",
    "print(f\"[Small training] Number of rows obtained after gruping frames per sequence: {len(seq_small_train_df)}\")\n",
    "print(f\"[Small validation] Number of rows obtained after gruping frames per sequence: {len(seq_small_val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8333631f-8130-4900-af44-4dda9496bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_train_df = seq_train_df[seq_train_df[\"sequence\"]!= \"\"].reset_index(drop=True)\n",
    "seq_val_df = seq_val_df[seq_val_df[\"sequence\"]!= \"\"].reset_index(drop=True)\n",
    "seq_small_train_df = seq_small_train_df[seq_small_train_df[\"sequence\"]!= \"\"].reset_index(drop=True)\n",
    "seq_small_val_df = seq_small_val_df[seq_small_val_df[\"sequence\"]!= \"\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4840bcc-26eb-47c7-be6a-436bd1a41c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 639121 entries, 0 to 639120\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   video     639121 non-null  object\n",
      " 1   frame     639121 non-null  int64 \n",
      " 2   class     639121 non-null  object\n",
      " 3   path      639121 non-null  object\n",
      " 4   sequence  639121 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "seq_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b3c4c52-50a0-4acd-80db-161f74f91f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 174686 entries, 0 to 174685\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   video     174686 non-null  object\n",
      " 1   frame     174686 non-null  int64 \n",
      " 2   class     174686 non-null  object\n",
      " 3   path      174686 non-null  object\n",
      " 4   sequence  174686 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "seq_val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38ba6c3a-2bfe-401e-8351-769eb860b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53346 entries, 0 to 53345\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   video     53346 non-null  object\n",
      " 1   frame     53346 non-null  int64 \n",
      " 2   class     53346 non-null  object\n",
      " 3   path      53346 non-null  object\n",
      " 4   sequence  53346 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "seq_small_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cb7d8c3-b85e-4a78-91f2-6999c82aee0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17947 entries, 0 to 17946\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   video     17947 non-null  object\n",
      " 1   frame     17947 non-null  int64 \n",
      " 2   class     17947 non-null  object\n",
      " 3   path      17947 non-null  object\n",
      " 4   sequence  17947 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 701.2+ KB\n"
     ]
    }
   ],
   "source": [
    "seq_small_val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cb32622-55fd-4f4f-a5a5-309399dbb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes\n",
    "seq_train_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"seq_train_df.pkl\"))\n",
    "seq_val_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"seq_val_df.pkl\"))\n",
    "test_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"test_df.pkl\"))\n",
    "seq_small_train_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"seq_small_train_df.pkl\"))\n",
    "seq_small_val_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"seq_small_val_df.pkl\"))\n",
    "small_test_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"small_test_df.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
