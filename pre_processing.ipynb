{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546630bd-2f5f-4490-a814-f653c60aa0e5",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97aa4c3-83b3-40b6-9c38-98436525a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter existing datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd5235b-5cd3-4184-9700-6debbbf3a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories and file paths\n",
    "DATASET_DIR = \"/mnt/f/ExoNet_Images/ExoNet_Images\"\n",
    "LABELS_FILE = \"/mnt/f/Descargas/Labels.csv\"\n",
    "FINAL_DATASETS_DIR = \"/mnt/f/Datasets/Tesis/\"\n",
    "IMAGE_PATH_FORMAT = \"{}/{}/['{}'] frame {}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ffbc59-6faf-4ec9-8299-e4eccd78614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 922782 entries, 0 to 922781\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   video   922782 non-null  object\n",
      " 1   frame   922782 non-null  int64 \n",
      " 2   class   922782 non-null  object\n",
      " 3   exist   922782 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 22.0+ MB\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(LABELS_FILE)\n",
    "labels[\"exist\"] = labels.apply(lambda row: os.path.exists(\n",
    "    IMAGE_PATH_FORMAT.format(\n",
    "        DATASET_DIR,\n",
    "        row.iloc[2],\n",
    "        row.iloc[0],\n",
    "        row.iloc[1])\n",
    "    ), axis=1)\n",
    "labels = labels[labels[\"exist\"] == True].reset_index(drop=True)\n",
    "labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848c052-3207-4add-a744-81bf4422bed9",
   "metadata": {},
   "source": [
    "Los frames de cada video tienen que ser agrupados en secuencia, de tal manera que la clasificación del último frame considere los frames previos de la secuencia. La secuencia elegida serán 20 frames previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e555ebd-83d1-45cf-a28f-02ab77766cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions: 39 - 11 - 6\n",
      "Shapes: train-(39,), val-(11,), test-(6,)\n"
     ]
    }
   ],
   "source": [
    "# Generate train, validation and test datasets from the original one\n",
    "np.random.seed(42)\n",
    "video_names = labels[\"video\"].unique()\n",
    "video_names = np.random.choice(video_names, replace=False, size=len(video_names))\n",
    "train_pct = int(len(video_names) * 0.7)\n",
    "val_pct = int(len(video_names) * 0.2)\n",
    "test_pct = int(len(video_names) - (train_pct + val_pct))\n",
    "print(f\"Proportions: {train_pct} - {val_pct} - {test_pct}\")\n",
    "train_videos, val_videos, test_videos = video_names[:train_pct], video_names[train_pct:train_pct+val_pct], video_names[train_pct+val_pct:]\n",
    "print(f\"Shapes: train-{train_videos.shape}, val-{val_videos.shape}, test-{test_videos.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da6fcef2-c8fa-4e8a-9064-5fd8294e6b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train records: 639667, Val records: 174840, Test records: 108275\n"
     ]
    }
   ],
   "source": [
    "train_df = labels[labels[\"video\"].isin(train_videos)].reset_index(drop=True)\n",
    "val_df = labels[labels[\"video\"].isin(val_videos)].reset_index(drop=True)\n",
    "test_df = labels[labels[\"video\"].isin(test_videos)].reset_index(drop=True)\n",
    "print(f\"Train records: {len(train_df)}, Val records: {len(val_df)}, Test records: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f87103a-10fe-476b-9ea2-8d0c809c36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna que contenga los paths a las imágenes\n",
    "def generate_filepath(row):\n",
    "    return IMAGE_PATH_FORMAT.format(DATASET_DIR,row[\"class\"],row[\"video\"],row[\"frame\"])\n",
    "    \n",
    "train_df.loc[:,'path'] = train_df.apply(generate_filepath, axis=1)\n",
    "val_df.loc[:,'path'] = val_df.apply(generate_filepath, axis=1)\n",
    "test_df.loc[:,'path'] = test_df.apply(generate_filepath, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ff60eda-88b8-484d-abfb-dfac341db3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the train_df and val_df datasets\n",
    "train_df.loc[:,'sequence'] = ''\n",
    "val_df.loc[:,'sequence'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "324f84bf-cc95-4427-978c-fd4b59123d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 639667 entries, 0 to 639666\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   video     639667 non-null  object\n",
      " 1   frame     639667 non-null  int64 \n",
      " 2   class     639667 non-null  object\n",
      " 3   exist     639667 non-null  bool  \n",
      " 4   path      639667 non-null  object\n",
      " 5   sequence  639667 non-null  object\n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 25.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112790b4-cc9e-40da-accb-5be9d3a0557f",
   "metadata": {},
   "source": [
    "According to the article where ExoNet database was proposed, each video was downsampled to 5 frames/s to minimize human annotations efforts. Therefore, each 5 video's frames represent 1 second of video recording. \n",
    "\n",
    "Training dataset must be splitted into fixed lenght sequences. Each sequence will represent a past time step (frame) of the video recording. Validation dataset will be splitted into sequences equals to training dataset. All frames in the test dataset will not suffer changes since it will simulate a real time video passed to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56d9ef20-6117-4090-840b-57c23fa6d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] Number of rows obtained after gruping frames per sequence: 639667\n",
      "[Validation] Number of rows obtained after gruping frames per sequence: 174840\n"
     ]
    }
   ],
   "source": [
    "# Sequence length will be set to 15 meaning that 3 past seconds will be considered to classify the current frame\n",
    "SEQUENCE_LENGTH = 15\n",
    "\n",
    "def group_frames_per_sequence(df, seq_len):\n",
    "    \"\"\"\n",
    "    Generar secuencias de imágenes de cada video.\n",
    "    [x1,x2,x3,...,xn] -> yn\n",
    "    Esto se traduce a:\n",
    "    [path1,path2,path3,...,path_n] -> yn\n",
    "    \"\"\"\n",
    "    balanced_df = None\n",
    "    _df = df.reset_index(drop=True)\n",
    "    for i in range(seq_len, len(df)+1):\n",
    "        tmp_df = _df.iloc[i-seq_len:i].copy()\n",
    "        _df.at[i-1,\"sequence\"] = \",\".join(tmp_df[\"path\"].to_list())\n",
    "    \n",
    "    return _df\n",
    "\n",
    "seq_train_df = train_df.groupby('video', group_keys=False)[['video','frame','class','path','sequence']].apply(lambda x: group_frames_per_sequence(x, SEQUENCE_LENGTH), include_groups=False)\n",
    "seq_train_df = seq_train_df.reset_index(drop=True)\n",
    "\n",
    "seq_val_df = val_df.groupby('video', group_keys=False)[['video','frame','class','path','sequence']].apply(lambda x: group_frames_per_sequence(x, SEQUENCE_LENGTH), include_groups=False)\n",
    "seq_val_df = seq_val_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"[Training] Number of rows obtained after gruping frames per sequence: {len(seq_train_df)}\")\n",
    "print(f\"[Validation] Number of rows obtained after gruping frames per sequence: {len(seq_val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8333631f-8130-4900-af44-4dda9496bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_train_df = seq_train_df[seq_train_df[\"sequence\"]!= \"\"].reset_index(drop=True)\n",
    "seq_val_df = seq_val_df[seq_val_df[\"sequence\"]!= \"\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4840bcc-26eb-47c7-be6a-436bd1a41c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 639121 entries, 0 to 639120\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   video     639121 non-null  object\n",
      " 1   frame     639121 non-null  int64 \n",
      " 2   class     639121 non-null  object\n",
      " 3   path      639121 non-null  object\n",
      " 4   sequence  639121 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "seq_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b3c4c52-50a0-4acd-80db-161f74f91f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 174686 entries, 0 to 174685\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   video     174686 non-null  object\n",
      " 1   frame     174686 non-null  int64 \n",
      " 2   class     174686 non-null  object\n",
      " 3   path      174686 non-null  object\n",
      " 4   sequence  174686 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "seq_val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cb32622-55fd-4f4f-a5a5-309399dbb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes\n",
    "seq_train_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"seq_train_df.pkl\"))\n",
    "seq_val_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"seq_val_df.pkl\"))\n",
    "test_df.to_pickle(os.path.join(FINAL_DATASETS_DIR, \"test_df.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
